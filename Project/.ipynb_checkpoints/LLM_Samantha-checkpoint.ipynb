{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81693ecdc88dbd36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:06.993364100Z",
     "start_time": "2023-11-18T16:37:58.113152500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import gradio as gr\n",
    "\n",
    "from textwrap import fill\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    )\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
    "\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eff7472620e5a9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:58.721260Z",
     "start_time": "2023-11-18T16:38:06.998517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin C:\\Users\\phili\\miniconda3\\envs\\ChildrensBook\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121_nocublaslt.dll\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Users\\phili\\miniconda3\\envs\\ChildrensBook\\bin\\cudart64_12.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 6.1\n",
      "CUDA SETUP: Detected CUDA version 121\n",
      "CUDA SETUP: Loading binary C:\\Users\\phili\\miniconda3\\envs\\ChildrensBook\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121_nocublaslt.dll...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaa0f0bcb94456da2a4605ce7f281e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "#MODEL_NAME = \"NousResearch/Yarn-Mistral-7b-128k\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, torch_dtype=torch.float16,\n",
    "    #use_flash_attention = True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c24c84de4e247c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:58.968145100Z",
     "start_time": "2023-11-18T16:38:58.737274800Z"
    }
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "generation_config.max_new_tokens = 2048\n",
    "generation_config.top_p = 0.95\n",
    "generation_config.do_sample = True\n",
    "#generation_config.repetition_penalty = 1.15\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "pipeline.model.config.pad_token_id = pipeline.model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef1910676d2f256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:58.983846600Z",
     "start_time": "2023-11-18T16:38:58.979334900Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipeline,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96ad765b0d5d387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.008823200Z",
     "start_time": "2023-11-18T16:38:58.995220700Z"
    }
   },
   "outputs": [],
   "source": [
    "longchat_template = \"\"\"<s>[INST]\n",
    "As a master storyteller, the AI's goal is to craft captivating, magical, and informative narratives for young audiences. The AI adopts a friendly tone, with rich scene descriptions and diverse, relatable characters. Key AI storytelling elements include:\n",
    "\n",
    "- Emphasizing positive themes: friendship, learning, curiosity, kindness.\n",
    "- Incorporating age-appropriate humor.\n",
    "- Using character adventures to present educational content engagingly.\n",
    "- Acknowledging information limits, underscoring continuous learning.\n",
    "- Introducing suitable challenges and emotions to develop resilience and empathy.\n",
    "- Offering varied story endings with hope or moral lessons, avoiding negative content like insults or frightening scenes.\n",
    "\n",
    "The AI's approach combines entertainment and education, aiming to inspire, amuse, and educate young readers.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "USER: {input}\n",
    "AI: [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642d1ee3c4c39aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.054551300Z",
     "start_time": "2023-11-18T16:38:58.999728700Z"
    }
   },
   "outputs": [],
   "source": [
    "longchat_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input\", \"history\"], template=longchat_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20dbf513ccc839a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.054551300Z",
     "start_time": "2023-11-18T16:38:59.018497200Z"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "# \n",
    "# conversation_buf = ConversationChain(\n",
    "#     llm=llm,\n",
    "#     memory=ConversationBufferMemory(ai_prefix=\"AI\", human_prefix=\"USER\"),\n",
    "#     prompt=longchat_prompt_template,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ce62d8346cb6fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.054551300Z",
     "start_time": "2023-11-18T16:38:59.019056Z"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "# \n",
    "# conversation_buf = ConversationChain(\n",
    "# \tllm=llm,\n",
    "# \tmemory=ConversationSummaryMemory(llm=llm, ai_prefix=\"AI\", human_prefix=\"USER\"),\n",
    "#   prompt=longchat_prompt_template\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da5e18709d94110",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.054551300Z",
     "start_time": "2023-11-18T16:38:59.031837600Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "conversation_buf = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=longchat_prompt_template,\n",
    "    memory=ConversationSummaryBufferMemory(\n",
    "        llm=llm,\n",
    "        max_token_limit=1300,\n",
    "        ai_prefix=\"AI\", \n",
    "        human_prefix=\"USER\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc39271ce40c00ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.054551300Z",
     "start_time": "2023-11-18T16:38:59.045880900Z"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationKGMemory\n",
    "# \n",
    "# conversation_buf = ConversationChain(\n",
    "# \tllm=llm,\n",
    "# \tmemory=ConversationKGMemory(llm=llm),\n",
    "#   prompt=longchat_prompt_template\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef30aa9a54eb9c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.089346300Z",
     "start_time": "2023-11-18T16:38:59.047889400Z"
    }
   },
   "outputs": [],
   "source": [
    "instruction_prompt = \"\"\"[INST] Create a children's book set in a magical world with dragons and Korean culture. The story, for young readers, will span 10 chapters, each focused on a unique adventure, blending wonder and Korean cultural elements. Each chapter should:\n",
    "\n",
    "    Be a narrative of at least 500 words!\n",
    "    Each chapter should have a open ending!\n",
    "    Start each chapter with the specific number and title!\n",
    "\n",
    "The AI must generate only one chapter at a time, pausing after each to await USER direction for the next chapter. \n",
    "Create only one detailed chapter. Never produce next chapters before the USER writes something![/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f368f64dfe47363d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:38:59.094355800Z",
     "start_time": "2023-11-18T16:38:59.063606800Z"
    }
   },
   "outputs": [],
   "source": [
    "special_prompt=\"\"\"[INST] Title: Magical Adventures in Korean Culture\n",
    "\n",
    "Objective: Create a 10-chapter children's book set in a magical world infused with Korean culture. Each chapter should be a 500-word narrative with an open ending and a unique title.\n",
    "\n",
    "AI Role: As a master storyteller, the AI crafts engaging and educational stories for young readers. The tone is friendly, focusing on positive themes like friendship and curiosity, and incorporating humor and educational content. Each story introduces challenges and concludes with hopeful or moral lessons.\n",
    "\n",
    "Process: The AI must generate only one chapter at a time, pausing after each to await USER direction for the next chapter. Create only one detailed chapter. Never produce next chapters before the USER writes something! \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45657100ddae421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:41:42.784064600Z",
     "start_time": "2023-11-18T16:38:59.065425100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_buf(instruction_prompt)[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c8ee1e887a32b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:43:01.956356500Z",
     "start_time": "2023-11-18T16:41:42.784064600Z"
    }
   },
   "outputs": [],
   "source": [
    "print(conversation_buf(f\"[INST] Give me 4 decision possibilities of how the story could continue! Write no more than two sentences. [/INST]\")[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e37fa419ded6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:57:16.824927500Z",
     "start_time": "2023-11-18T16:43:01.956356500Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "num_chapters = 10\n",
    "num_dec = 4  # number of decisions\n",
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "if num_dec > len(letters):\n",
    "    num_dec = len(letters)\n",
    "for i in range(num_chapters-2):\n",
    "    decision = random.choice(letters[:num_dec])\n",
    "    print(f\"Decision: {decision}\")\n",
    "    print(conversation_buf(special_prompt + f\" Continue the story with decision {decision}. Create the next chapter now! Keep in mind to write at least 500 words! [/INST]\")[\"response\"])\n",
    "    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "    print(conversation_buf(f\"[INST] Give me four decision possibilities of how the story could continue. Write no more than two sentences. [/INST]\")[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb08c45ab9a9be3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:57:16.824927500Z"
    }
   },
   "outputs": [],
   "source": [
    "decision = \"c\"\n",
    "print(conversation_buf(f\"[INST] Continue the story with decision {decision}. Create the next and last chapter now! Keep in mind to write at least 500 words! Find a happy or sad ending based on the previous decisions. [/INST]\")[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845ba48eb57e1ab",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:57:16.824927500Z"
    }
   },
   "outputs": [],
   "source": [
    "print(conversation_buf.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a7d393b2f2f1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:57:16.836935600Z",
     "start_time": "2023-11-18T16:57:16.824927500Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
