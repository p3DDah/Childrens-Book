{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7f9a261e8dd0>\n",
      "NVIDIA A100-SXM4-80GB\n",
      "12.1\n",
      "GPU 0:\n",
      "  Total Memory: 81092.56 MB\n",
      "  Allocated Memory: 0.00 MB\n",
      "  Cached Memory: 0.00 MB\n",
      "--------------------------------------------------\n",
      "tensor([1., 2.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}:\")\n",
    "        gpu_properties = torch.cuda.get_device_properties(i)\n",
    "\n",
    "        # Total memory\n",
    "        total_memory = gpu_properties.total_memory / 1024**2  # Convert to MB\n",
    "        print(f\"  Total Memory: {total_memory:.2f} MB\")\n",
    "\n",
    "        # Current memory usage\n",
    "        allocated_memory = torch.cuda.memory_allocated(i) / 1024**2  # Convert to MB\n",
    "        print(f\"  Allocated Memory: {allocated_memory:.2f} MB\")\n",
    "\n",
    "        # Cached memory\n",
    "        cached_memory = torch.cuda.memory_reserved(i) / 1024**2  # Convert to MB\n",
    "        print(f\"  Cached Memory: {cached_memory:.2f} MB\")\n",
    "\n",
    "        print(\"--------------------------------------------------\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU detected.\")\n",
    "\n",
    "print(torch.tensor([1.0, 2.0], device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c4c803b95f896c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "from diffusers import UniPCMultistepScheduler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e565eafeb18a9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bc5ec99bc346bd81e93f7f38c5bab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\", device_map=\"auto\")\n",
    "#base.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a8faa6f4bf4a49",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base.scheduler = UniPCMultistepScheduler.from_config(base.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e1125daf54a798",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_steps = 30\n",
    "high_noise_frac = 0.8\n",
    "prompt = \"a photo of an astronaut high resolution, unreal engine, ultra realistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5611e8eb9e313a0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d560d103ebd4ec3ac62ba5d7ca5fd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "image = base(\n",
    "    prompt=prompt,\n",
    "    generator=torch.Generator(\"cuda\").manual_seed(0),\n",
    "    num_inference_steps=n_steps,\n",
    ").images[0]\n",
    "#image\n",
    "image.save(f'result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d83c0c43e61189",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
