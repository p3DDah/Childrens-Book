{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import init_LLM_PURE, init_LLM_STORY, init_SDXL, init_Translator, init_TTM\n",
    "from models import LLM_story, SDXL, TL, TTM\n",
    "from utils import ordinal, check_GPU, translate_decisions\n",
    "import logging\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Set up basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_PURE_ = init_LLM_PURE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDXL_, DETECTOR_ = init_SDXL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dict = init_Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTM_ = init_TTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_models():\n",
    "#     LLM_PURE_ = init_LLM_PURE()\n",
    "#     SDXL_, DETECTOR_ = init_SDXL\n",
    "#     language_dict = init_Translator\n",
    "#     TTM_ = init_TTM\n",
    "#     \n",
    "#     return LLM_PURE_, SDXL_, TTM_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current memory usage\n",
    "import torch\n",
    "allocated_memory = torch.cuda.memory_allocated(0) / 1024**2  # Convert to MB\n",
    "print(f\"  Allocated Memory: {allocated_memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_gen(Params, LLM_PURE_): # after configuration page, while reading the prolog\n",
    "    #update Params\n",
    "    keys_to_update = [\"main_name\", \"gender\"]\n",
    "    for key in keys_to_update:\n",
    "        if key in Params:\n",
    "            Params[key] = TL(Params[key], from_code=Params[\"language\"])\n",
    "    \n",
    "    LLM_STORY_ = init_LLM_STORY(LLM_PURE_, Params)\n",
    "    LLM_STORY_, chapter, text = LLM_story(LLM_STORY_, \"Write now only the 1st chapter!\", \"story\", LLM_PURE_) # type: ignore\n",
    "    LLM_STORY_, decisions = LLM_story(LLM_STORY_, f\"Create now {Params['num_decisions']} decisions how the story could continue.\", \"decisions\", LLM_PURE_) # type: ignore\n",
    "    \n",
    "    image_path = SDXL(SDXL_, DETECTOR_, LLM_PURE_, text, chap=1, decision=1)\n",
    "    sound_path = TTM(TTM_, LLM_PURE_, text, chap=1, decision=1, use_ai_music=Params[\"use_ai_music\"])\n",
    "    \n",
    "    language = Params[\"language\"]\n",
    "    Params[\"prev_sounds\"].append(sound_path)\n",
    "    return LLM_STORY_, TL(text, to_code=language), TL(chapter, to_code=language), translate_decisions(decisions, TL, language), image_path, sound_path, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_gen(Params, LLM_STORY_, LLM_PURE_, chap_num, decision):\n",
    "    LLM_STORY_, chapter, text = LLM_story(LLM_STORY_, f\"Write now the {ordinal(chap_num)} chapter of {params['num_chapters']} with using decision {decision}.\", \"story\", LLM_PURE_) # type: ignore\n",
    "    LLM_STORY_, decisions = LLM_story(LLM_STORY_, f\"Create now {Params['num_decisions']} decisions how the story could continue.\", \"decisions\", LLM_PURE_) # type: ignore\n",
    "    \n",
    "    image_path = SDXL(SDXL_, DETECTOR_, LLM_PURE_, text, chap_num, decision)\n",
    "    sound_path = TTM(TTM_, LLM_PURE_, text, chap_num, decision, Params[\"prev_sounds\"], Params[\"use_ai_music\"])\n",
    "    \n",
    "    language = Params[\"language\"]\n",
    "    Params[\"prev_sounds\"].append(sound_path)\n",
    "    # Keep only the last two items\n",
    "    if len(Params[\"prev_sounds\"]) > 2:\n",
    "        Params[\"prev_sounds\"] = Params[\"prev_sounds\"][-2:]\n",
    "    return LLM_STORY_, TL(text, to_code=language), TL(chapter, to_code=language), translate_decisions(decisions, TL, language), image_path, sound_path, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_gen(Params, LLM_STORY_, LLM_PURE_, chap_num, decision):\n",
    "    LLM_STORY_, chapter, text = LLM_story(LLM_STORY_, f\"Write now the {ordinal(chap_num)} chapter of {params['num_chapters']} with using decision {decision}. Find a happy or sad ending based on the previous decisions.\", \"story\", LLM_PURE_) # type: ignore\n",
    "\n",
    "    image_path = SDXL(SDXL_, DETECTOR_, LLM_PURE_, text, chap_num, decision)\n",
    "    sound_path = TTM(TTM_, LLM_PURE_, text, chap_num, decision, Params[\"prev_sounds\"], Params[\"use_ai_music\"])\n",
    "    \n",
    "    language = Params[\"language\"]\n",
    "    Params[\"prev_sounds\"].append(sound_path)\n",
    "    # Keep only the last two items\n",
    "    if len(Params[\"prev_sounds\"]) > 2:\n",
    "        Params[\"prev_sounds\"] = Params[\"prev_sounds\"][-2:]\n",
    "    return LLM_STORY_, TL(text, to_code=language), TL(chapter, to_code=language), image_path, sound_path, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_gen(Params, LLM_STORY_, LLM_PURE_):\n",
    "    LLM_STORY_, chapter, text = LLM_story(LLM_STORY_, f\"Write now a detailed text to evaluate the decisions of {params['main_name']}, and show what was good or bad and why! Please call {params['main_name']} by you. Write as chapter 'Reflections of your Adventure'\", \"story\", LLM_PURE_) # type: ignore\n",
    "\n",
    "    sound_path = TTM(TTM_, LLM_PURE_, text, Params[\"num_chapters\"]+1, 1, Params[\"prev_sounds\"], Params[\"use_ai_music\"])\n",
    "    \n",
    "    language = Params[\"language\"]\n",
    "    Params[\"prev_sounds\"].append(sound_path)\n",
    "    # Keep only the last two items\n",
    "    if len(Params[\"prev_sounds\"]) > 2:\n",
    "        Params[\"prev_sounds\"] = Params[\"prev_sounds\"][-2:]\n",
    "\n",
    "    return TL(text, to_code=language), TL(chapter, to_code=language), sound_path, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"main_name\"] = \"Klaus\"\n",
    "params[\"gender\"] = \"male\"\n",
    "params[\"language\"] = \"en\"\n",
    "params[\"country\"] = \"south korea\"\n",
    "params[\"colour\"] = \"blue\"\n",
    "params[\"animal\"] = \"crocodile\"\n",
    "params[\"animal_name\"] = \"Chris P Bacon\"\n",
    "params[\"season\"] = \"winter\"\n",
    "params[\"num_decisions\"] = 4\n",
    "params[\"num_chapters\"] = 3\n",
    "params[\"use_ai_music\"] = True\n",
    "params[\"prev_sounds\"] = []\n",
    "\n",
    "LLM_STORY_, cur_story, chapter_title, decisions, image_path, sound_path, params = start_gen(params, LLM_PURE_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapter_title)\n",
    "print(cur_story)\n",
    "print(decisions)\n",
    "print(image_path)\n",
    "print(sound_path)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_STORY_, cur_story, chapter_title, decisions, image_path, sound_path, params = next_gen(params, LLM_STORY_, LLM_PURE_, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapter_title)\n",
    "print(cur_story)\n",
    "print(decisions)\n",
    "print(image_path)\n",
    "print(sound_path)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_STORY_, cur_story, chapter_title, image_path, sound_path, params = last_gen(params, LLM_STORY_, LLM_PURE_, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapter_title)\n",
    "print(cur_story)\n",
    "print(image_path)\n",
    "print(sound_path)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_story, chapter_title, sound_path, params = con_gen(params, LLM_STORY_, LLM_PURE_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapter_title)\n",
    "print(cur_story)\n",
    "print(sound_path)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_STORY_.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
